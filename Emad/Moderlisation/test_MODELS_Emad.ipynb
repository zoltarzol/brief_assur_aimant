{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "# sklearn.compose: The sklearn.compose module is a submodule of the sklearn library for machine learning in Python. It provides functions for creating complex preprocessing and modeling pipelines.\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PolynomialFeatures,RobustScaler\n",
    "#sklearn.preprocessing: The sklearn.preprocessing module is a submodule of the sklearn library that provides functions for preprocessing data, such as scaling and normalizing features, imputing missing values, and encoding categorical variables.\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso\n",
    "# sklearn.linear_model: The sklearn.linear_model module is a submodule of the sklearn library that provides functions for fitting linear models for regression and classification.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# sklearn.pipeline: The sklearn.pipeline module is a submodule of the sklearn library that provides functions for creating and working with pipelines of transformers and models.\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,learning_curve, RandomizedSearchCV\n",
    "# sklearn.model_selection: The sklearn.model_selection module is a submodule of the sklearn library that provides functions for splitting data into training and test sets, evaluating models using cross-validation, and hyperparameter tuning.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# sklearn.dummy: The sklearn.dummy module is a submodule of the sklearn library that provides simple dummy models for regression and classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges   bmi_class\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400  overweight\n",
      "1   18    male  33.770         1     no  southeast   1725.55230       obese\n",
      "2   28    male  33.000         3     no  southeast   4449.46200       obese\n",
      "3   33    male  22.705         0     no  northwest  21984.47061      normal\n",
      "4   32    male  28.880         0     no  northwest   3866.85520  overweight\n"
     ]
    }
   ],
   "source": [
    "# chargement et affichage des donn√©es\n",
    "data = pd.read_csv('../data.csv')\n",
    "def classify_bmi(row):\n",
    "    if row[\"bmi\"] < 25:\n",
    "        return \"normal\"\n",
    "    elif row[\"bmi\"] < 30:\n",
    "        return \"overweight\"\n",
    "    else:\n",
    "        return \"obese\"\n",
    "\n",
    "data[\"bmi_class\"] = data.apply(classify_bmi, axis=1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        1338 non-null   int64  \n",
      " 1   sex        1338 non-null   object \n",
      " 2   bmi        1338 non-null   float64\n",
      " 3   children   1338 non-null   int64  \n",
      " 4   smoker     1338 non-null   object \n",
      " 5   region     1338 non-null   object \n",
      " 6   charges    1338 non-null   float64\n",
      " 7   bmi_class  1338 non-null   object \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1337, 8)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the 'data' DataFrame\n",
    "df = data.drop_duplicates()\n",
    "\n",
    "# Print the number of rows and columns in the cleaned DataFrame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1337, 1)\n",
      "(1337, 7)\n"
     ]
    }
   ],
   "source": [
    "# Select the 'charges' column and store it in a separate DataFrame\n",
    "y = df[['charges']]\n",
    "\n",
    "# Drop the 'charges' column from the 'data' DataFrame and store the rest of the columns in a separate DataFrame\n",
    "X = df.drop(columns=['charges'])\n",
    "\n",
    "# Print the shape of the 'y' and 'X' DataFrames\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.8, random_state=42)\n",
    "# shuffle: This is a boolean parameter that determines whether the data should be shuffled before splitting. If True, the data will be shuffled randomly before the split. If False, the data will be split in the order it is in the DataFrame.\n",
    "# train_size: This is a float parameter that determines the proportion of the data that should be included in the training set. For example, if train_size=0.8, 80% of the data will be included in the training set and the remaining 20% will be included in the test set.\n",
    "# random_state: This is an optional integer parameter that sets the random seed for shuffling the data. This can be useful for reproducibility of the split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy = DummyRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "numerical_features = make_column_selector(dtype_include=np.number)\n",
    "categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "\n",
    "# Create a preprocessing pipeline for numerical features\n",
    "numerical_pipeline = make_pipeline(StandardScaler())\n",
    "\n",
    "# Create a preprocessing pipeline for categorical features\n",
    "categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "# The handle_unknown parameter of the OneHotEncoder transformer in scikit-learn is used to specify how the transformer should handle categorical levels (i.e., categories) that are present in the test data but not in the training data.\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features),(categorical_pipeline, categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054717970876826"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, LinearRegression())\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67616826 0.7768447  0.73834607 0.73636039 0.77490605 0.68236163\n",
      " 0.78436305 0.76235248 0.70033763 0.60316271]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8204970129593311"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def train_and_validate_regression_model(data_path, target_column, shuffle, train_size, random_state, cv):\n",
    "  df = pd.read_csv(data_path)\n",
    "  df = df.drop_duplicates()\n",
    "  y = df[[target_column]]\n",
    "  X = df.drop(columns=[target_column])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=shuffle, train_size=train_size, random_state=random_state, stratify=X[['smoker']])\n",
    "  numerical_features = make_column_selector(dtype_include=np.number)\n",
    "  categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "  numerical_pipeline = make_pipeline(StandardScaler())\n",
    "  categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "  preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "  model = make_pipeline(preprocessor, LinearRegression())\n",
    "  scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "  model.fit(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  return scores, test_score\n",
    "\n",
    "\n",
    "scores, test_score = train_and_validate_regression_model('../data.csv', 'charges', True, 0.8, 42, 10)\n",
    "print(scores)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6979856  0.67572351 0.76802403 0.70980435 0.76070805]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8204970129593311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_validate_regression_model(data_path, target_column, shuffle, train_size, random_state, n_splits):\n",
    "  df = pd.read_csv(data_path)\n",
    "  df = df.drop_duplicates()\n",
    "  y = df[[target_column]]\n",
    "  X = df.drop(columns=[target_column])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=shuffle, train_size=train_size, random_state=random_state, stratify=X[['smoker']])\n",
    "  numerical_features = make_column_selector(dtype_include=np.number)\n",
    "  categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "  numerical_pipeline = make_pipeline(StandardScaler())\n",
    "  categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "  preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "  model = make_pipeline(preprocessor, LinearRegression())\n",
    "\n",
    "  kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "  scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "  model.fit(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  return scores, test_score\n",
    "\n",
    "\n",
    "scores, test_score = train_and_validate_regression_model('../data.csv', 'charges', True, 0.8, 42, n_splits=5)\n",
    "print(scores)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 50.0}\n",
      "[0.70254937 0.70111686 0.70702414 0.63858058 0.70989915 0.81545106\n",
      " 0.71928002 0.69648111 0.70360675 0.81746816]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8210936451530005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_validate_regression_model(data_path, target_column, shuffle, train_size, random_state, cv, n_splits):\n",
    "  df = pd.read_csv(data_path)\n",
    "  df = df.drop_duplicates()\n",
    "  y = df[[target_column]]\n",
    "  X = df.drop(columns=[target_column])\n",
    "  \n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=shuffle, train_size=train_size, random_state=random_state, stratify=X[['smoker']])\n",
    "  \n",
    "  numerical_features = make_column_selector(dtype_include=np.number)\n",
    "  categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "  numerical_pipeline = make_pipeline(StandardScaler())\n",
    "  categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "  preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "  \n",
    "  model = make_pipeline(preprocessor, Lasso())\n",
    "  param_grid = {'lasso__alpha': np.linspace(0.1,100,1000)}\n",
    "  grid_search = GridSearchCV(model, param_grid, cv=cv)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  best_params = grid_search.best_params_\n",
    "  print(best_params)\n",
    "  model = grid_search.best_estimator_\n",
    "  \n",
    "  kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "  scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "  model.fit(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  return scores, test_score\n",
    "\n",
    "\n",
    "scores, test_score = train_and_validate_regression_model('../data.csv', 'charges', True, 0.8, 42, 5, 10)\n",
    "print(scores)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "728166df596dc6b9d95aa00a68d9d66253e0ab53dc6b17d60ab3234c59362003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
