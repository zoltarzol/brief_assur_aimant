{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer, make_column_transformer\n",
    "# sklearn.compose: The sklearn.compose module is a submodule of the sklearn library for machine learning in Python. It provides functions for creating complex preprocessing and modeling pipelines.\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PolynomialFeatures,RobustScaler\n",
    "#sklearn.preprocessing: The sklearn.preprocessing module is a submodule of the sklearn library that provides functions for preprocessing data, such as scaling and normalizing features, imputing missing values, and encoding categorical variables.\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso, ElasticNet\n",
    "# sklearn.linear_model: The sklearn.linear_model module is a submodule of the sklearn library that provides functions for fitting linear models for regression and classification.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# sklearn.pipeline: The sklearn.pipeline module is a submodule of the sklearn library that provides functions for creating and working with pipelines of transformers and models.\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,learning_curve, RandomizedSearchCV, cross_val_score, KFold\n",
    "# sklearn.model_selection: The sklearn.model_selection module is a submodule of the sklearn library that provides functions for splitting data into training and test sets, evaluating models using cross-validation, and hyperparameter tuning.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# sklearn.dummy: The sklearn.dummy module is a submodule of the sklearn library that provides simple dummy models for regression and classification.\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from scipy.stats import probplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import my_functions\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement et affichage des données\n",
    "data = pd.read_csv('../data.csv')\n",
    "def classify_bmi(row):\n",
    "    if row[\"bmi\"] < 25:\n",
    "        return \"normal\"\n",
    "    elif row[\"bmi\"] < 30:\n",
    "        return \"overweight\"\n",
    "    else:\n",
    "        return \"obese\"\n",
    "\n",
    "data[\"bmi_class\"] = data.apply(classify_bmi, axis=1)\n",
    "\n",
    "# Remove duplicates from the 'data' DataFrame\n",
    "df = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chargement et affichage des données\n",
    "#data = pd.read_csv('../data.csv')\n",
    "#def classify_bmi(row):\n",
    "#    if row[\"bmi\"] < 18.5:\n",
    "#        return \"underweight\"\n",
    "#    elif row[\"bmi\"] < 25:\n",
    "#        return \"normal\"\n",
    "#    elif row[\"bmi\"] < 30:\n",
    "#        return \"overweight\"\n",
    "#    elif row[\"bmi\"] < 35:\n",
    "#        return \"obese\"\n",
    "#    else:\n",
    "#        return \"severely obese\"\n",
    "#data[\"bmi_class\"] = data.apply(classify_bmi, axis=1)\n",
    "## Remove duplicates from the 'data' DataFrame\n",
    "#df = data.drop_duplicates()\n",
    "## Drop Bmi\n",
    "#df.drop(\"bmi\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'charges' column and store it in a separate DataFrame\n",
    "y = df[['charges']]\n",
    "# Drop the 'charges' column from the 'data' DataFrame and store the rest of the columns in a separate DataFrame\n",
    "X = df.drop(columns=['charges'])\n",
    "metrics = []\n",
    "\n",
    "def make_pipeline_to_ML(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.8, random_state=42, stratify=X[['smoker']])\n",
    "    numerical_features = make_column_selector(dtype_include=np.number)\n",
    "    categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "    numerical_pipeline = make_pipeline(StandardScaler(with_mean=False))\n",
    "    categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "    preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "    return preprocessor, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train) : 1069\n",
      "New len(X_train) : 1023\n"
     ]
    }
   ],
   "source": [
    "preprocessor, X_train, X_test, y_train, y_test = make_pipeline_to_ML(X,y)\n",
    "print(f\"len(X_train) : {len(X_train)}\")\n",
    "index_to_be_removed = my_functions.get_index_to_remove_by_Cooks_Distance(X_train=X_train, y_train=y_train, preprocessor=preprocessor)\n",
    "X_train = X_train.drop(index=index_to_be_removed.values)\n",
    "y_train = y_train.drop(index=index_to_be_removed.values)\n",
    "print(f\"New len(X_train) : {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, LR_model_1 = my_functions.LR_with_CV(PolynomialFeatures_degree = 1, \n",
    "                    X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                    preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                    isplot = False, isinfo = False, include_learning_curve = False) \n",
    "    \n",
    "metrics.append([\"LR with Kfold CV (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, \n",
    "                    Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, LR_model_2 = my_functions.LR_with_CV(PolynomialFeatures_degree = 2, \n",
    "                    X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                    preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                    isplot = False, isinfo = False, include_learning_curve = False) \n",
    "    \n",
    "metrics.append([\"LR with Kfold CV (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, \n",
    "                    Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################################\n",
    "#\n",
    "# Get best Hypermarameters\n",
    "#\n",
    "################################\n",
    "################################\n",
    "\n",
    "\n",
    "#my_functions.get_best_params(\n",
    "#    PolynomialFeatures_degree = 2,  \n",
    "#    model=Lasso(max_iter=100000, \n",
    "#    tol=0.0001,\n",
    "#    random_state=42, \n",
    "#    selection='cyclic'),   \n",
    "#    param_grid= {'lasso__alpha': np.linspace(30,40,200)}, \n",
    "#    preprocessor = preprocessor, \n",
    "#    X_train = X_train, \n",
    "#    y_train = y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Lasso_model_1 = my_functions.LASSO_with_CV(PolynomialFeatures_degree = 1, Best_alpha= 39.4321608040201,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "\n",
    "metrics.append([\"LASSO (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, \n",
    "                Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Lasso_model_2 = my_functions.LASSO_with_CV(PolynomialFeatures_degree = 2, Best_alpha= 39.4321608040201,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "\n",
    "metrics.append([\"LASSO (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, \n",
    "                Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = my_functions.get_best_params(PolynomialFeatures_degree = 1,  model=Ridge(max_iter=100000, tol=0.0001,random_state=42),   param_grid= {'ridge__alpha': np.linspace(1,3,200)}, preprocessor = preprocessor, X_train = X_train, y_train = y_train)\n",
    "#best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Ridge_model_1 = my_functions.Ridge_with_CV(PolynomialFeatures_degree = 1, Best_alpha=  1.4623115577889447,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "metrics.append([\"Ridg (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Ridge_model_2 = my_functions.Ridge_with_CV(PolynomialFeatures_degree = 2, Best_alpha=  1.4623115577889447,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "metrics.append([\"Ridg (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = my_functions.get_best_params(PolynomialFeatures_degree = 2,  model=ElasticNet(max_iter=100000, tol=0.0001,random_state=42),   param_grid = {'elasticnet__alpha': np.linspace(49, 51, 200), \n",
    "#                 'elasticnet__l1_ratio': [0.9999999]}, \n",
    "#                 preprocessor = preprocessor, X_train = X_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Best_elasticnet__l1_ratio, ElasticNet_model_1 = my_functions.ElasticNet_with_CV(PolynomialFeatures_degree =1, Best_alpha = 33.24120603015076, \n",
    "    Best_elasticnet__l1_ratio = 0.9999999, \n",
    "    X_train = X_train, y_train = y_train \n",
    "    , X_test = X_test , y_test = y_test, \n",
    "    preprocessor = preprocessor , shuffle=True, \n",
    "    random_state=42, isplot= False, isinfo = False, include_learning_curve = False)\n",
    "\n",
    "metrics.append([\"ElasticNet (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)} Best_ratio : {round(Best_elasticnet__l1_ratio,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Best_elasticnet__l1_ratio, ElasticNet_model_2 = my_functions.ElasticNet_with_CV(PolynomialFeatures_degree =2, Best_alpha = 50.00502512562814, \n",
    "    Best_elasticnet__l1_ratio = 0.5, \n",
    "    X_train = X_train, y_train = y_train \n",
    "    , X_test = X_test , y_test = y_test, \n",
    "    preprocessor = preprocessor , shuffle=True, \n",
    "    random_state=42, isplot= False, isinfo = False, include_learning_curve = False)\n",
    "\n",
    "metrics.append([\"ElasticNet (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}  Best_ratio : {round(Best_elasticnet__l1_ratio,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Score (test)</th>\n",
       "      <th>Score (trainging)</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>HyperParamter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO (Polynomial degree=2)</th>\n",
       "      <td>0.9167</td>\n",
       "      <td>1406.289577</td>\n",
       "      <td>3284.148115</td>\n",
       "      <td>0.925181</td>\n",
       "      <td>0.931742</td>\n",
       "      <td>0.9289 (+/- 0.03)</td>\n",
       "      <td>Best_alpha : 39.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridg (Polynomial degree=2)</th>\n",
       "      <td>0.9156</td>\n",
       "      <td>1405.073555</td>\n",
       "      <td>3316.223550</td>\n",
       "      <td>0.923712</td>\n",
       "      <td>0.933860</td>\n",
       "      <td>0.9260 (+/- 0.03)</td>\n",
       "      <td>Best_alpha : 1.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR with Kfold CV (Polynomial degree=2)</th>\n",
       "      <td>0.9155</td>\n",
       "      <td>1413.818544</td>\n",
       "      <td>3319.371160</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.933942</td>\n",
       "      <td>0.9254 (+/- 0.03)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO (Polynomial degree=1)</th>\n",
       "      <td>0.7717</td>\n",
       "      <td>3862.598915</td>\n",
       "      <td>5146.517520</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>0.827428</td>\n",
       "      <td>0.8217 (+/- 0.02)</td>\n",
       "      <td>Best_alpha : 39.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet (Polynomial degree=1)</th>\n",
       "      <td>0.7723</td>\n",
       "      <td>3870.753779</td>\n",
       "      <td>5149.934507</td>\n",
       "      <td>0.816019</td>\n",
       "      <td>0.827520</td>\n",
       "      <td>0.8217 (+/- 0.02)</td>\n",
       "      <td>Best_alpha : 33.241 Best_ratio : 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridg (Polynomial degree=1)</th>\n",
       "      <td>0.7740</td>\n",
       "      <td>3909.130917</td>\n",
       "      <td>5166.050964</td>\n",
       "      <td>0.814866</td>\n",
       "      <td>0.827780</td>\n",
       "      <td>0.8211 (+/- 0.02)</td>\n",
       "      <td>Best_alpha : 1.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR with Kfold CV (Polynomial degree=1)</th>\n",
       "      <td>0.7756</td>\n",
       "      <td>3916.188022</td>\n",
       "      <td>5168.887972</td>\n",
       "      <td>0.814663</td>\n",
       "      <td>0.827796</td>\n",
       "      <td>0.8210 (+/- 0.02)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet (Polynomial degree=2)</th>\n",
       "      <td>-2.1233</td>\n",
       "      <td>5992.040493</td>\n",
       "      <td>8225.730305</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.527054</td>\n",
       "      <td>0.5175 (+/- 0.01)</td>\n",
       "      <td>Best_alpha : 50.005  Best_ratio : 0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            R2          MAE         RMSE  \\\n",
       "Model                                                                      \n",
       "LASSO (Polynomial degree=2)             0.9167  1406.289577  3284.148115   \n",
       "Ridg (Polynomial degree=2)              0.9156  1405.073555  3316.223550   \n",
       "LR with Kfold CV (Polynomial degree=2)  0.9155  1413.818544  3319.371160   \n",
       "LASSO (Polynomial degree=1)             0.7717  3862.598915  5146.517520   \n",
       "ElasticNet (Polynomial degree=1)        0.7723  3870.753779  5149.934507   \n",
       "Ridg (Polynomial degree=1)              0.7740  3909.130917  5166.050964   \n",
       "LR with Kfold CV (Polynomial degree=1)  0.7756  3916.188022  5168.887972   \n",
       "ElasticNet (Polynomial degree=2)       -2.1233  5992.040493  8225.730305   \n",
       "\n",
       "                                        Score (test)  Score (trainging)  \\\n",
       "Model                                                                     \n",
       "LASSO (Polynomial degree=2)                 0.925181           0.931742   \n",
       "Ridg (Polynomial degree=2)                  0.923712           0.933860   \n",
       "LR with Kfold CV (Polynomial degree=2)      0.923567           0.933942   \n",
       "LASSO (Polynomial degree=1)                 0.816263           0.827428   \n",
       "ElasticNet (Polynomial degree=1)            0.816019           0.827520   \n",
       "Ridg (Polynomial degree=1)                  0.814866           0.827780   \n",
       "LR with Kfold CV (Polynomial degree=1)      0.814663           0.827796   \n",
       "ElasticNet (Polynomial degree=2)            0.530628           0.527054   \n",
       "\n",
       "                                              CV Accuracy  \\\n",
       "Model                                                       \n",
       "LASSO (Polynomial degree=2)             0.9289 (+/- 0.03)   \n",
       "Ridg (Polynomial degree=2)              0.9260 (+/- 0.03)   \n",
       "LR with Kfold CV (Polynomial degree=2)  0.9254 (+/- 0.03)   \n",
       "LASSO (Polynomial degree=1)             0.8217 (+/- 0.02)   \n",
       "ElasticNet (Polynomial degree=1)        0.8217 (+/- 0.02)   \n",
       "Ridg (Polynomial degree=1)              0.8211 (+/- 0.02)   \n",
       "LR with Kfold CV (Polynomial degree=1)  0.8210 (+/- 0.02)   \n",
       "ElasticNet (Polynomial degree=2)        0.5175 (+/- 0.01)   \n",
       "\n",
       "                                                                HyperParamter  \n",
       "Model                                                                          \n",
       "LASSO (Polynomial degree=2)                               Best_alpha : 39.432  \n",
       "Ridg (Polynomial degree=2)                                 Best_alpha : 1.462  \n",
       "LR with Kfold CV (Polynomial degree=2)                                   None  \n",
       "LASSO (Polynomial degree=1)                               Best_alpha : 39.432  \n",
       "ElasticNet (Polynomial degree=1)         Best_alpha : 33.241 Best_ratio : 1.0  \n",
       "Ridg (Polynomial degree=1)                                 Best_alpha : 1.462  \n",
       "LR with Kfold CV (Polynomial degree=1)                                   None  \n",
       "ElasticNet (Polynomial degree=2)        Best_alpha : 50.005  Best_ratio : 0.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result = pd.DataFrame(metrics , columns=['Model' , 'R2' , 'MAE' , 'RMSE', 'Score (test)', 'Score (trainging)' , \"CV Accuracy\", 'HyperParamter']).sort_values(['CV Accuracy'] , ascending=False, ignore_index=True).set_index('Model')\n",
    "#df_result = pd.DataFrame(metrics , columns=['Model' , 'R2' , 'MAE' , 'RMSE', 'Score (test)', 'Score (trainging)' , \"CV Accuracy\"]).sort_values(['MAE' , 'RMSE'] , ignore_index=True).set_index('Model')\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"Lasso_Model.pkl\", \"wb\") \n",
    "pickle.dump(Lasso_model_2, pickle_out) \n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'bmi_class'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
