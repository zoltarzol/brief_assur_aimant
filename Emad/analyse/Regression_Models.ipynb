{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer, make_column_transformer\n",
    "# sklearn.compose: The sklearn.compose module is a submodule of the sklearn library for machine learning in Python. It provides functions for creating complex preprocessing and modeling pipelines.\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PolynomialFeatures,RobustScaler\n",
    "#sklearn.preprocessing: The sklearn.preprocessing module is a submodule of the sklearn library that provides functions for preprocessing data, such as scaling and normalizing features, imputing missing values, and encoding categorical variables.\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso, ElasticNet\n",
    "# sklearn.linear_model: The sklearn.linear_model module is a submodule of the sklearn library that provides functions for fitting linear models for regression and classification.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# sklearn.pipeline: The sklearn.pipeline module is a submodule of the sklearn library that provides functions for creating and working with pipelines of transformers and models.\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,learning_curve, RandomizedSearchCV, cross_val_score, KFold\n",
    "# sklearn.model_selection: The sklearn.model_selection module is a submodule of the sklearn library that provides functions for splitting data into training and test sets, evaluating models using cross-validation, and hyperparameter tuning.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# sklearn.dummy: The sklearn.dummy module is a submodule of the sklearn library that provides simple dummy models for regression and classification.\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from scipy.stats import probplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import my_functions\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement et affichage des données\n",
    "data = pd.read_csv('../data.csv')\n",
    "def classify_bmi(row):\n",
    "    if row[\"bmi\"] < 25:\n",
    "        return \"normal\"\n",
    "    elif row[\"bmi\"] < 30:\n",
    "        return \"overweight\"\n",
    "    else:\n",
    "        return \"obese\"\n",
    "\n",
    "data[\"bmi_class\"] = data.apply(classify_bmi, axis=1)\n",
    "\n",
    "# Remove duplicates from the 'data' DataFrame\n",
    "df = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chargement et affichage des données\n",
    "#data = pd.read_csv('../data.csv')\n",
    "#def classify_bmi(row):\n",
    "#    if row[\"bmi\"] < 18.5:\n",
    "#        return \"underweight\"\n",
    "#    elif row[\"bmi\"] < 25:\n",
    "#        return \"normal\"\n",
    "#    elif row[\"bmi\"] < 30:\n",
    "#        return \"overweight\"\n",
    "#    elif row[\"bmi\"] < 35:\n",
    "#        return \"obese\"\n",
    "#    else:\n",
    "#        return \"severely obese\"\n",
    "#data[\"bmi_class\"] = data.apply(classify_bmi, axis=1)\n",
    "## Remove duplicates from the 'data' DataFrame\n",
    "#df = data.drop_duplicates()\n",
    "## Drop Bmi\n",
    "#df.drop(\"bmi\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'charges' column and store it in a separate DataFrame\n",
    "y = df[['charges']]\n",
    "# Drop the 'charges' column from the 'data' DataFrame and store the rest of the columns in a separate DataFrame\n",
    "X = df.drop(columns=['charges'])\n",
    "metrics = []\n",
    "\n",
    "def make_pipeline_to_ML(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.8, random_state=42, stratify=X[['smoker']])\n",
    "    numerical_features = make_column_selector(dtype_include=np.number)\n",
    "    categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "    numerical_pipeline = make_pipeline(StandardScaler(with_mean=False))\n",
    "    categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))\n",
    "    preprocessor = make_column_transformer((numerical_pipeline, numerical_features),\n",
    "                                    (categorical_pipeline, categorical_features)\n",
    "                                    )\n",
    "    return preprocessor, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor, X_train, X_test, y_train, y_test = make_pipeline_to_ML(X,y)\n",
    "\n",
    "\n",
    "#### Cook Distance \n",
    "\n",
    "#print(f\"len(X_train) : {len(X_train)}\")\n",
    "#index_to_be_removed = my_functions.get_index_to_remove_by_Cooks_Distance(X_train=X_train, y_train=y_train, preprocessor=preprocessor)\n",
    "#X_train = X_train.drop(index=index_to_be_removed.values)\n",
    "#y_train = y_train.drop(index=index_to_be_removed.values)\n",
    "#print(f\"New len(X_train) : {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, LR_model_1 = my_functions.LR_with_CV(PolynomialFeatures_degree = 1, \n",
    "                    X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                    preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                    isplot = False, isinfo = False, include_learning_curve = False) \n",
    "    \n",
    "metrics.append([\"LR with Kfold CV (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, \n",
    "                    Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, LR_model_2 = my_functions.LR_with_CV(PolynomialFeatures_degree = 2, \n",
    "                    X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                    preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                    isplot = False, isinfo = False, include_learning_curve = False) \n",
    "    \n",
    "metrics.append([\"LR with Kfold CV (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, \n",
    "                    Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################################\n",
    "#\n",
    "# Get best Hypermarameters\n",
    "#\n",
    "################################\n",
    "################################\n",
    "\n",
    "\n",
    "#my_functions.get_best_params(\n",
    "#    PolynomialFeatures_degree = 2,  \n",
    "#    model=Lasso(max_iter=100000, \n",
    "#    tol=0.0001,\n",
    "#    random_state=42, \n",
    "#    selection='cyclic'),   \n",
    "#    param_grid= {'lasso__alpha': np.linspace(30,40,200)}, \n",
    "#    preprocessor = preprocessor, \n",
    "#    X_train = X_train, \n",
    "#    y_train = y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Lasso_model_1 = my_functions.LASSO_with_CV(PolynomialFeatures_degree = 1, Best_alpha= 39.4321608040201,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "\n",
    "metrics.append([\"LASSO (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, \n",
    "                Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Lasso_model_2 = my_functions.LASSO_with_CV(PolynomialFeatures_degree = 2, Best_alpha= 39.4321608040201,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "\n",
    "metrics.append([\"LASSO (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, \n",
    "                Model_score_training, \"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = my_functions.get_best_params(PolynomialFeatures_degree = 1,  model=Ridge(max_iter=100000, tol=0.0001,random_state=42),   param_grid= {'ridge__alpha': np.linspace(1,3,200)}, preprocessor = preprocessor, X_train = X_train, y_train = y_train)\n",
    "#best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Ridge_model_1 = my_functions.Ridge_with_CV(PolynomialFeatures_degree = 1, Best_alpha=  1.4623115577889447,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "metrics.append([\"Ridg (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Ridge_model_2 = my_functions.Ridge_with_CV(PolynomialFeatures_degree = 2, Best_alpha=  1.4623115577889447,\n",
    "                X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, \n",
    "                preprocessor = preprocessor, shuffle=True, random_state=42,\n",
    "                isplot = False, isinfo = False, include_learning_curve = False) \n",
    "\n",
    "metrics.append([\"Ridg (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = my_functions.get_best_params(PolynomialFeatures_degree = 2,  model=ElasticNet(max_iter=100000, tol=0.0001,random_state=42),   param_grid = {'elasticnet__alpha': np.linspace(49, 51, 200), \n",
    "#                 'elasticnet__l1_ratio': [0.9999999]}, \n",
    "#                 preprocessor = preprocessor, X_train = X_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Best_elasticnet__l1_ratio, ElasticNet_model_1 = my_functions.ElasticNet_with_CV(PolynomialFeatures_degree =1, Best_alpha = 33.24120603015076, \n",
    "    Best_elasticnet__l1_ratio = 0.9999999, \n",
    "    X_train = X_train, y_train = y_train \n",
    "    , X_test = X_test , y_test = y_test, \n",
    "    preprocessor = preprocessor , shuffle=True, \n",
    "    random_state=42, isplot= False, isinfo = False, include_learning_curve = False)\n",
    "\n",
    "metrics.append([\"ElasticNet (Polynomial degree=1)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)} Best_ratio : {round(Best_elasticnet__l1_ratio,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MAE, RMSE, Model_score_test, Model_score_training, scores_mean, scores_std, Best_alpha, Best_elasticnet__l1_ratio, ElasticNet_model_2 = my_functions.ElasticNet_with_CV(PolynomialFeatures_degree =2, Best_alpha = 50.00502512562814, \n",
    "    Best_elasticnet__l1_ratio = 0.999999, \n",
    "    X_train = X_train, y_train = y_train \n",
    "    , X_test = X_test , y_test = y_test, \n",
    "    preprocessor = preprocessor , shuffle=True, \n",
    "    random_state=42, isplot= False, isinfo = False, include_learning_curve = False)\n",
    "\n",
    "metrics.append([\"ElasticNet (Polynomial degree=2)\", R2, MAE, RMSE, Model_score_test, Model_score_training ,\"%0.4f (+/- %0.2f)\" % (scores_mean, scores_std), f\"Best_alpha : {round(Best_alpha,3)}  Best_ratio : {round(Best_elasticnet__l1_ratio,3)}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Score (test)</th>\n",
       "      <th>Score (trainging)</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>HyperParamter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LASSO (Polynomial degree=2)</th>\n",
       "      <td>0.9124</td>\n",
       "      <td>1957.294489</td>\n",
       "      <td>3340.682271</td>\n",
       "      <td>0.922583</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.8488 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 39.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet (Polynomial degree=2)</th>\n",
       "      <td>0.9124</td>\n",
       "      <td>1960.457382</td>\n",
       "      <td>3335.036643</td>\n",
       "      <td>0.922844</td>\n",
       "      <td>0.857777</td>\n",
       "      <td>0.8488 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 50.005  Best_ratio : 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridg (Polynomial degree=2)</th>\n",
       "      <td>0.9088</td>\n",
       "      <td>2029.465675</td>\n",
       "      <td>3419.335355</td>\n",
       "      <td>0.918894</td>\n",
       "      <td>0.861147</td>\n",
       "      <td>0.8432 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 1.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR with Kfold CV (Polynomial degree=2)</th>\n",
       "      <td>0.9080</td>\n",
       "      <td>2059.129706</td>\n",
       "      <td>3441.722650</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.861231</td>\n",
       "      <td>0.8395 (+/- 0.04)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO (Polynomial degree=1)</th>\n",
       "      <td>0.7717</td>\n",
       "      <td>3655.599830</td>\n",
       "      <td>5092.514964</td>\n",
       "      <td>0.820099</td>\n",
       "      <td>0.739239</td>\n",
       "      <td>0.7286 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 39.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet (Polynomial degree=1)</th>\n",
       "      <td>0.7724</td>\n",
       "      <td>3662.001424</td>\n",
       "      <td>5094.071744</td>\n",
       "      <td>0.819989</td>\n",
       "      <td>0.739371</td>\n",
       "      <td>0.7285 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 33.241 Best_ratio : 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR with Kfold CV (Polynomial degree=1)</th>\n",
       "      <td>0.7759</td>\n",
       "      <td>3708.067361</td>\n",
       "      <td>5107.965335</td>\n",
       "      <td>0.819006</td>\n",
       "      <td>0.739695</td>\n",
       "      <td>0.7282 (+/- 0.04)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridg (Polynomial degree=1)</th>\n",
       "      <td>0.7743</td>\n",
       "      <td>3706.798635</td>\n",
       "      <td>5107.543835</td>\n",
       "      <td>0.819036</td>\n",
       "      <td>0.739682</td>\n",
       "      <td>0.7282 (+/- 0.04)</td>\n",
       "      <td>Best_alpha : 1.462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            R2          MAE         RMSE  \\\n",
       "Model                                                                      \n",
       "LASSO (Polynomial degree=2)             0.9124  1957.294489  3340.682271   \n",
       "ElasticNet (Polynomial degree=2)        0.9124  1960.457382  3335.036643   \n",
       "Ridg (Polynomial degree=2)              0.9088  2029.465675  3419.335355   \n",
       "LR with Kfold CV (Polynomial degree=2)  0.9080  2059.129706  3441.722650   \n",
       "LASSO (Polynomial degree=1)             0.7717  3655.599830  5092.514964   \n",
       "ElasticNet (Polynomial degree=1)        0.7724  3662.001424  5094.071744   \n",
       "LR with Kfold CV (Polynomial degree=1)  0.7759  3708.067361  5107.965335   \n",
       "Ridg (Polynomial degree=1)              0.7743  3706.798635  5107.543835   \n",
       "\n",
       "                                        Score (test)  Score (trainging)  \\\n",
       "Model                                                                     \n",
       "LASSO (Polynomial degree=2)                 0.922583           0.858246   \n",
       "ElasticNet (Polynomial degree=2)            0.922844           0.857777   \n",
       "Ridg (Polynomial degree=2)                  0.918894           0.861147   \n",
       "LR with Kfold CV (Polynomial degree=2)      0.917829           0.861231   \n",
       "LASSO (Polynomial degree=1)                 0.820099           0.739239   \n",
       "ElasticNet (Polynomial degree=1)            0.819989           0.739371   \n",
       "LR with Kfold CV (Polynomial degree=1)      0.819006           0.739695   \n",
       "Ridg (Polynomial degree=1)                  0.819036           0.739682   \n",
       "\n",
       "                                              CV Accuracy  \\\n",
       "Model                                                       \n",
       "LASSO (Polynomial degree=2)             0.8488 (+/- 0.04)   \n",
       "ElasticNet (Polynomial degree=2)        0.8488 (+/- 0.04)   \n",
       "Ridg (Polynomial degree=2)              0.8432 (+/- 0.04)   \n",
       "LR with Kfold CV (Polynomial degree=2)  0.8395 (+/- 0.04)   \n",
       "LASSO (Polynomial degree=1)             0.7286 (+/- 0.04)   \n",
       "ElasticNet (Polynomial degree=1)        0.7285 (+/- 0.04)   \n",
       "LR with Kfold CV (Polynomial degree=1)  0.7282 (+/- 0.04)   \n",
       "Ridg (Polynomial degree=1)              0.7282 (+/- 0.04)   \n",
       "\n",
       "                                                                HyperParamter  \n",
       "Model                                                                          \n",
       "LASSO (Polynomial degree=2)                               Best_alpha : 39.432  \n",
       "ElasticNet (Polynomial degree=2)        Best_alpha : 50.005  Best_ratio : 1.0  \n",
       "Ridg (Polynomial degree=2)                                 Best_alpha : 1.462  \n",
       "LR with Kfold CV (Polynomial degree=2)                                   None  \n",
       "LASSO (Polynomial degree=1)                               Best_alpha : 39.432  \n",
       "ElasticNet (Polynomial degree=1)         Best_alpha : 33.241 Best_ratio : 1.0  \n",
       "LR with Kfold CV (Polynomial degree=1)                                   None  \n",
       "Ridg (Polynomial degree=1)                                 Best_alpha : 1.462  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result = pd.DataFrame(metrics , columns=['Model' , 'R2' , 'MAE' , 'RMSE', 'Score (test)', 'Score (trainging)' , \"CV Accuracy\", 'HyperParamter']).sort_values(['CV Accuracy'] , ascending=False, ignore_index=True).set_index('Model')\n",
    "#df_result = pd.DataFrame(metrics , columns=['Model' , 'R2' , 'MAE' , 'RMSE', 'Score (test)', 'Score (trainging)' , \"CV Accuracy\"]).sort_values(['MAE' , 'RMSE'] , ignore_index=True).set_index('Model')\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"Lasso_Model.pkl\", \"wb\") \n",
    "pickle.dump(Lasso_model_2, pickle_out) \n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "728166df596dc6b9d95aa00a68d9d66253e0ab53dc6b17d60ab3234c59362003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
